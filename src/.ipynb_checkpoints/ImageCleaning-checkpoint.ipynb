{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import time\n",
    "\n",
    "import utils as utils\n",
    "import image_generation as imgen\n",
    "from imshow3D import imshow3D\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.array([1, 1, 1])\n",
    "sizeI = np.array([64, 64, 64])\n",
    "pts = utils.random_seed_locations(1000, sizeI)\n",
    "\n",
    "I = utils.seedBeadsN(pts, sizeI, sigma)\n",
    "imshow3D(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = [x for x in range(0,64,8)]\n",
    "len(slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2531716823577881\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f443c57fb1249b1b4802632234eca4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Slice plane selection:', index=1, options=('x-y', 'y-z', 'z-x'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<imshow3D.imshow3D at 0x7f8989be89e8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "psf = sio.loadmat('../data/psf.mat')\n",
    "psf = psf['psf']\n",
    "\n",
    "slices = [x for x in range(14, 114, 5)]\n",
    "sizei = np.array([64,64,128])\n",
    "sigmapts = {200:1.5*np.array([1,1,1]), 100:1.75*np.array([1,1,1]), 50:2*np.array([1,1,1])}\n",
    "im_range = {'lower':0.2, 'upper':0.2, 'gap':0.6}\n",
    "gauss_noise = {'mean':0, 'std':0.02}\n",
    "I_noise, I = imgen.create_im_2D(20, sizei, slices, sigmapts, psf,snr=12, \n",
    "                                im_range=im_range, gauss_noise=gauss_noise)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "imshow3D(np.squeeze(np.append(I, I_noise, axis=2)), 0, (12,12))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices = [x for x in range(14, 114, 5)]\n",
    "len(slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psf = sio.loadmat('../data/psf.mat')\n",
    "psf = psf['psf'][:,:,5]\n",
    "psf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.array([1, 1])\n",
    "sizeI = np.array([64, 64])\n",
    "pts = utils.random_seed_locations(100, sizeI)\n",
    "\n",
    "I = utils.seedBeadsN(pts, sizeI, sigma)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(I, cmap='magma')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_noise = utils.add_poisson_noise(I, 3)\n",
    "I_noise = utils.add_gaussian_noise(I_noise, 0, 0.15)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(I_noise, vmax=1, cmap='magma')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate image dataset\n",
    "n_images_train = 50000\n",
    "n_images_test = 5000\n",
    "sizeI = np.array([64,64])\n",
    "nPts = 100\n",
    "sigma = np.array([1,1])\n",
    "snr = 3\n",
    "gauss_noise = {'mean':0, 'std':0.15}\n",
    "im_range = {'lower':0.2, 'upper':0.8}\n",
    "\n",
    "train_X, train_y = utils.create_im(n_images_train, sizeI, nPts, sigma, snr, gauss_noise, im_range)\n",
    "test_X, test_y = utils.create_im(n_images_test, sizeI, nPts, sigma, snr, gauss_noise, im_range)\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(np.squeeze(test_y[0,:,:,:]), vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameter\n",
    "learning_rate = 0.001\n",
    "batch_size = 20\n",
    "epochs = 25\n",
    "display_step = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input and target placeholders\n",
    "inputs_ = tf.placeholder(tf.float32, (None,64,64,1), name=\"input\")\n",
    "targets_ = tf.placeholder(tf.float32, (None,64,64,1), name=\"input\")\n",
    "\n",
    "### Define Encoder\n",
    "def encoder(x):\n",
    "    \n",
    "    # Layer 1: Conv to 32x32x15\n",
    "    conv1 = tf.layers.conv2d(inputs=x, \n",
    "                             filters=15, \n",
    "                             kernel_size=(5,5),\n",
    "                             strides=(2,2),\n",
    "                             padding='same',\n",
    "                             activation=tf.nn.relu)\n",
    "        \n",
    "    # Layer 2: Conv to 16x16x30\n",
    "    conv2 = tf.layers.conv2d(inputs=conv1, \n",
    "                             filters=30, \n",
    "                             kernel_size=(5,5),\n",
    "                             strides=(2,2),\n",
    "                             padding='same',\n",
    "                             activation=tf.nn.relu)\n",
    "    \n",
    "    # Layer 3: Conv to 8x8x45\n",
    "    conv3 = tf.layers.conv2d(inputs=conv2, \n",
    "                             filters=45, \n",
    "                             kernel_size=(5,5),\n",
    "                             strides=(2,2),\n",
    "                             padding='same',\n",
    "                             activation=tf.nn.relu)\n",
    "    return conv3\n",
    "\n",
    "### Define Decoder\n",
    "def decoder(x):\n",
    "    \n",
    "    # Layer 4: Conv_transpose to 16x16x45\n",
    "    conv_t4 = tf.layers.conv2d_transpose(inputs=x, \n",
    "                                         filters=45, \n",
    "                                         kernel_size=(3,3),\n",
    "                                         strides=(2,2),\n",
    "                                         padding='same',\n",
    "                                         activation=tf.nn.relu)\n",
    "    \n",
    "    # Layer 5: Conv_transpose to 32x32x30\n",
    "    conv_t5 = tf.layers.conv2d_transpose(inputs=conv_t4, \n",
    "                                         filters=30, \n",
    "                                         kernel_size=(5,5),\n",
    "                                         strides=(2,2),\n",
    "                                         padding='same',\n",
    "                                         activation=tf.nn.relu)\n",
    "    \n",
    "    # Layer 6: Conv_transpose to 64x64x15\n",
    "    conv_t6 = tf.layers.conv2d_transpose(inputs=conv_t5, \n",
    "                                         filters=15, \n",
    "                                         kernel_size=(5,5),\n",
    "                                         strides=(2,2),\n",
    "                                         padding='same',\n",
    "                                         activation=tf.nn.relu)\n",
    "\n",
    "    # Layer 6: Conv_transpose to 128x128x10\n",
    "    conv_t7 = tf.layers.conv2d_transpose(inputs=conv_t6, \n",
    "                                         filters=10, \n",
    "                                         kernel_size=(5,5),\n",
    "                                         strides=(1,1),\n",
    "                                         padding='same',\n",
    "                                         activation=tf.nn.relu)\n",
    "    \n",
    "    # Layer 7: Conv to 64x64x1\n",
    "    conv7 = tf.layers.conv2d(inputs=conv_t7, \n",
    "                             filters=1, \n",
    "                             kernel_size=(3,3),\n",
    "                             strides =(1,1),\n",
    "                             padding='same', \n",
    "                             activation=None)\n",
    "    \n",
    "    # Make logits \n",
    "    logits = tf.slice(conv7, [0, 0, 0, 0], [-1, 64, 64, 1]) \n",
    "    \n",
    "    return logits\n",
    "\n",
    "### Construct model\n",
    "encoded = encoder(inputs_)\n",
    "logits = decoder(encoded)\n",
    "\n",
    "# Pass logits through sigmoid to get reconstructed image\n",
    "decoded = tf.nn.sigmoid(logits)\n",
    "\n",
    "# Pass logits through sigmoid and calculate the cross-entropy loss\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "\n",
    "# Get cost and define the optimizer\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i in range(train_X.shape[0]//batch_size - 1):\n",
    "        imgs_X = train_X[i*batch_size:(i+1)*batch_size,:,:,:]\n",
    "        imgs_y = train_y[i*batch_size:(i+1)*batch_size,:,:,:]\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: imgs_X,\n",
    "                                                         targets_: imgs_y})\n",
    "         # Display logs per step\n",
    "        if i % display_step == 0:\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}/{}...\".format(i+1, train_X.shape[0]//batch_size),\n",
    "                  \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "canvas = np.empty((64 * n, 64*3))\n",
    "# canvas_recon = np.empty((28 * m, 28 * n))\n",
    "\n",
    "# Encode and decode the digit image\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    imgs_X = test_X[i*n:(i+1)*n,:,:,:]\n",
    "    imgs_y = test_y[i*n:(i+1)*n,:,:,:]\n",
    "    output = sess.run(decoded, feed_dict={inputs_: imgs_X})\n",
    "    # Draw the generated digits\n",
    "    canvas[i*64 : (i+1)*64, 0:64] = np.squeeze(imgs_X[i,:,:,:])\n",
    "    canvas[i*64 : (i+1)*64, 64:128] = output[i].reshape([64, 64])\n",
    "    canvas[i*64 : (i+1)*64, 128:192] = np.squeeze(imgs_y[i,:,:,:])\n",
    "\n",
    "print(\"Original Images\")     \n",
    "plt.figure(figsize=(18,6*n))\n",
    "plt.imshow(canvas, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "canvas = np.empty((64 * n, 64*3))\n",
    "# canvas_recon = np.empty((28 * m, 28 * n))\n",
    "\n",
    "# Encode and decode the digit image\n",
    "imgs_X = train_X[i*n:(i+1)*n,:,:,:]\n",
    "imgs_y = train_y[i*n:(i+1)*n,:,:,:]\n",
    "output = sess.run(decoded, feed_dict={inputs_: imgs_X})\n",
    "\n",
    "for i in range(n):\n",
    "    # Draw the generated digits\n",
    "    canvas[i*64 : (i+1)*64, 0:64] = np.squeeze(imgs_X[i,:,:,:])\n",
    "    canvas[i*64 : (i+1)*64, 64:128] = output[i].reshape([64, 64])\n",
    "    canvas[i*64 : (i+1)*64, 128:192] = np.squeeze(imgs_y[i,:,:,:])\n",
    "\n",
    "print(\"Original Images\")     \n",
    "plt.figure(figsize=(18,6*n))\n",
    "plt.imshow(canvas, vmax=1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(np.squeeze(test_y[0,:,:,:]), vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(output[2].reshape([64, 64]), vmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
